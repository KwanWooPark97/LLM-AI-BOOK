# 자신의 데이터에 맞춘 임베딩 모델 만들기  
앞에서 교차 인코더와 바이 인코더를 공부했다.  
교차 인코더는 문장을 직접 비교하기 때문에 유사도를 더 정확히 계산할 수 있지만 느리고 확장성이 떨어진다.  
바이 인ㅋ노더는 독립적인 문장 임베딩을 생성하고 임베딩끼리 유사도 같은 가벼운 계산을 하기 때문에 빠르게 비슷한 문장을 찾을 수 있다.  
이번 장에서는 먼저 느리지만 정화갛ㄴ 교차 인코더와 빠르지만 덜 정확한 바이 인코더를 결합해 RAG의 검색 성능을 높이는 방법을 알아본다.  
BERT와 같은 인코더 모델을 가져와 우리 데이터에 맞게 미세 조정하여 사용한다.  

## 검색 성능을 높이기 위한 두 가지 방법  
![https://github.com/KwanWooPark97/LLM-AI-BOOK/blob/main/img/11_1.png](https://github.com/KwanWooPark97/LLM-AI-BOOK/blob/main/img/11_1.png)   

위 그림처럼 교차 인코더와 바이 인코더를 결합해 사용할 수 있다.  
바이 인코더를 사용해 대규모의 문서에서 검색 쿼리와 유사한 소수의 문서를 선별한다.  
소수의 문서는 유사도를 더 정확히 계산할 수 있는 교차 인코더를 사용해 유사한 순서대로 재정렬한다.  
이때 검색 성능을 높이기 위한 방법은 두 가지로 나눌 수 있다.  
먼저 바이 인코더를 추가 학습해 성능을 높인다. 앞에서 사용한 인코더는 사전 학습된 모델을 그냥 가져와서 사용했기 때문에 우리 데이터에 최적화된 상태가 아니였다.  
다음으로 교차 인코더를 추가해 검색 성능을 높일 수 있다. 앞에서는 바이 인코더만 사용했었다. 이를 통해 더욱 관련성이 높은 문서를 고를 수 있다.  
RAG에서는 검색된 모든 문서를 프롬프트에 추가하지 않고 상위 몇 개의 입력만 프롬프트에 추가한다. 따라서 검색 쿼리와 관련이 높은 문서가 상위 검색 결과에 포함되어야 RAG가 효과적으로 작동한다.  


## 언어 모델을 임베딩 모델로 만들기  
보통 문장 임베딩 모델은 2개의 층으로 나뉜다.  
첫 번째 층은 대량의 텍스트 데이터로 사전 학습한 BERT나 RoBERTa 같은 언어 모델이다.  
두 번째 층은 입력 문장의 길이에 따라 달라질 수 있는 출력 차원을 고정된 차원으로 맞추는 역할을 한다.  
이거에 대한 이해는 확실히 코드를 보고 수식을 이해하면 쉽다. 예제 코드 처음에 정리해놨다.  

### 대조 학습  
문장 임베딩 모델을 학습시킬 때는 일반적으로 대조 학습을 사용한다.  
대조 학습이란 관련이 있거나 유사한 데이터는 가까워지게 만들고 반대인 경우 멀어지게 만든다.  
만약 두개의 문장(A와 B)가 있을 때 유사한 데이터인 경우는 가깝게 아닌 경우는 멀게한다.  
또는 서로 이어지는 문장이라면 가깝게 아니면 멀어지게 또는 서로 질문과 답변 관계인 경우 가깝게 아닌 경우 멀도록 학습을 시킨다.  
이제 예제 코드로 들어가자   

## 임베딩 모델 미세 조정하기  
RAG는 검색 쿼리와 관련도니 문서를 찾아 프롬프트에 맥락 데이터로 추가할 때 임베딩 모델을 활용한다. 그러므로 좋은 임베딩 모델이라면 검색 쿼리와 관련이 있는 문서는 유사도가 높게 나오고 아니면 낮게 나와야한다.  
이번 절에서는 MRC 데이터셋으로 추가 학습시켜, 실습 데이터의 유사도를 더 잘 계산할 수 있도록 만든다.  
실습 코드 11.11 ㄱ  

### MNR 손실을 활용해 미세 조정하기  
앞에서는 코사인 유사도 LOSS를 사용했으므로 새로운 MNR(Multiple Negatives Ranking) loss를 사용해 미세 조정한다.  
MNR loss는 MRC 데이터셋 처럼 데이터셋에 서로 관련이 있는 문장만 있는 경우 사용하기 좋은 손실 함수이다.  
앞의 절에서 예제를 실행하며 억지로 서로 관련이 없는 데이터를 만들어서 학습을 시켰는데 MNR을 사용하면 그걸 알아서 해준다.  
바로 예제 11.17 ㄱㄱ  

## 검색 품질을 높이는 순위 재정렬  
위에서 설명했듯이 바이 인코더와 교차 인코더는 각자의 장단점이 존재한다.  
이런 장단점을 보완하기 위해 먼저 바이 인코더로 후보군을 압축하고 후보군 내에서 교차 인코더로 순위를 재정렬하는 방법을 사용할 수 있다.  
교차 인코더로는 일반적으로 3장에서 본 문장 분류 모델을 활용한다. 유사도를 계산하는 문제는 결국 2개의 문장을 입력으로 받아 관련이 있는지 없는지 확인하는 분류 문제로 귀결되기 떄문이다.  
예제 11.23 ㄱㄱ  

## 바이 인코더와 교차 인코더로 개선된 RAG 구현하기  

