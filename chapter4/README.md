# LLM의 기본 상식을 쌓자  
LLM은 다음 단어를 예측하는 방식으로 대량의 텍스트를 학습해서 뛰어난 텍스트 생성 능력을 보여줬다.  
하지만 초기 GPT-3는 이 방식으로 학습했지만 사용자의 요청에 적절히 응답하기보다는 사용자의 말에 이어질 법한 텍스트를 생성했다는 한계가있었다.  
##### 
그럼 어떻게 챗 GPT를 만들었을까?
1. 네이버 지식인과 같은 요청과 답변 형식으로 된 지시 데이터셋(instruction dataset) 을 통해 GPT-3가 사용자의 요청에 응답할 수 있도록 학습시켰다.
2. 사용자가 더 좋아하고 사용자에게 더 도움이 되는 답변을 생성할 수 있도록 추가학습을 시켰다.(여기서 RLHF랑 DPO같은 기술들이 나왔겠지?)
####
****
위에 2번 방식에서 사람들이 더 선호하는 답변을 생성할 수 있도록 모델을 조정하는 방법은 크게 강화학습을 사용하는 방법과 사용하지 않는 방법으로 나눌수있다.  
맨 처음 챗GPT는 PPO를 이용해서 학습시켰지만 PPO의 고질적인 문제인 하이퍼파라미터에 예민하고 이에 따른 학습이 불안정해서 문제가 많이 있었다.  
그래서 안쓰는 기술들이 개발되고 있는데 대표적인게 DPO이다.  
(공부할때 이책을 선택한 이유가 RLHF와 DPO를 설명해준다는 점이 매우 호감이였음)  
####
****
이미 알고있지만 LLM은 보통 인터넷상에 있는 다양한 텍스트 데이터를 수집한 대용량의 텍스트로 사전 학습한다. 2023년 메타에서 공개한 라마-2 모델은 약 10TB 분량의 텍스트를 사전 학습에 사용했는데  
사전 학습 데이터의 경우 코드, 블로그, 기사, 광고 등 다양한 글이 섞여있기 때문에 사전 학습 데이터에서 다음 단어를 예측하는 방법으로 학습하는 경우 LLM이 특정한 형태로 응답하거나 사용자의 요청에 따라 응답하길 기대하기는 어렵다.  
사전 학습 동안은 LLM이 언어에 대한 전체적인 이해도가 높아지고 바로 다음에 올 단어를 점점 더 잘 예측하게된다.  
(데이터가 다양한 형태이고 사용자의 뭔가가 들어가는 경우가 아니라 진짜 다음 단어만 예측하게 학습만 한다는 뜻같음 나중에 사용자 요청에 대한 학습을 따로 진행)  

![https://github.com/KwanWooPark97/LLM-AI-BOOK/blob/main/img/4_train.png](https://github.com/KwanWooPark97/LLM-AI-BOOK/blob/main/img/4_train.png)
####  
****
LLM도 사용자의 요청에 적절히 응답하기 위해서는 사람이 코딩 테스트를 준비할 때와 비슷하게 요청의 형식을 적절히 해석하고 응답의 형태를 적절히 작성하며 요청과 응답이 잘 연결되도록 추가로 학습한다.  
이를 지도 미세 조정(supervised fine-tuning)이라고 한다.  
학습 데이터에 정답이 있으므로 "지도"가 붙었다.  
지도 미세 조정을 통해 LLM은 사용자의 요청에 맞춰 응답하도록 학습하는데, 이를 정렬(alignment)라고 한다. 사람의 요청과 LLM의 응답이 정렬되도록 한다는 의미이다.  
지도 미세 조정에 사용하는 학습 데이터를 지시 테이터셋(instruction dataset)이라고 부른다. 지시 데이터셋에 비해 사전 학습 데이터셋은 형식이 너무 다양하고, 사용자의 요청에 응답하는 형식의 데이터는 적다.  
이런 문제를 보완하기 위해 사용자의 요구사항과 그에 대한 응답을 구조화한 데이터를 구축하고 언어 모델의 학습에 활용한다.  
위에서 말했듯 지시 데이터셋은 사용자의 요청을 형식에 맞춰 작성하고, 그에 대해 적절한 형식의 응답을 하는 형태다. OpenAI는 이걸 만들기 위해 레이블러를 고용해 13000개가 넘는 지시 데이터셋을 구축해서 학습했다.   
![https://github.com/KwanWooPark97/LLM-AI-BOOK/blob/main/img/4_ins.png](https://github.com/KwanWooPark97/LLM-AI-BOOK/blob/main/img/4_ins.png)  
위 사진에서 응답을 레이블러가 직접 작성한다.
지시 데이터셋은 실제로 어떤 형태일까?  
https://huggingface.co/datasets/tatsu-lab/alpaca  
위 링크로 들어가면 알파카에 사용한 데이터셋을 볼 수 있다.   
####  
****  
![https://github.com/KwanWooPark97/LLM-AI-BOOK/blob/main/img/4_data.png](https://github.com/KwanWooPark97/LLM-AI-BOOK/blob/main/img/4_data.png)  
지시사항은 사용자의 요구사항을 표현한 문장이다. 입력에는 답변을 하는 데 필요한 데이터가 들어간다. 출력은 지시사항과 입력을 바탕으로 한 정답 응답이다. 텍스트는 지시사항, 입력, 출력을 정해진 포맷으로 하나로 묶은 데이터이다.  
데이터를 보면 지시사항, 입력 ,출력이 있는데 이것을 지시 데이터셋으로 구조화 한 것이 text 부분이다.  
첫 두 줄에서 "작업을 설명한 지시사항과 맥락 정보인 입력을 바탕으로 요청에 대한 적절한 응답을 작성하라"라는 안내를 하고 앞의 것들을 전부 넣어준다.  
이때 LLM이 데이터의 형식을 인식할 수 있도록 ###으로 텍스트를 구분해준다.  
데이터 셋이 어떻게 생겼는지는 확인했다. 그럼 어떻게 학습을 진행할까?  
그냥 사전 학습 때와 동일하게 다음 단어를 예측하는 인과적 언어 모델링(causal language modeling)을 사용해 학습한다. 즉, 지도 미세 조정이라는 이름은 LLM이 학습하는 방식이 달라서가 아니라 학습 데이터셋에 차이가 있어서 지어진것이다.  
####
****
## 좋은 지시 데이터셋이 갖춰야 할 조건  

